{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F370Gflfm-bP"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load IMDB dataset\n",
        "\n",
        "num_words = 10000  # Only consider the top 10,000 words\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)"
      ],
      "metadata": {
        "id": "c06Ku8qC3TMK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data\n",
        "\n",
        "max_review_length = 500\n",
        "x_train = pad_sequences(x_train, maxlen=max_review_length)\n",
        "x_test = pad_sequences(x_test, maxlen=max_review_length)"
      ],
      "metadata": {
        "id": "lo5RKs1wobZB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "embedding_vector_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words, embedding_vector_length, input_length=max_review_length))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "GA3Fm2_bxRZr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "LOmWemCNxpJP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra9PwiOExRWM",
        "outputId": "b65cb22e-984c-4397-a32a-d499bb50ee07"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 64s 156ms/step - loss: 0.4604 - accuracy: 0.7771 - val_loss: 0.3314 - val_accuracy: 0.8592\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 34s 87ms/step - loss: 0.2682 - accuracy: 0.8966 - val_loss: 0.3154 - val_accuracy: 0.8692\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.2118 - accuracy: 0.9194 - val_loss: 0.3497 - val_accuracy: 0.8466\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f02b6a83ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Accuracy: {:.2f}%\".format(scores[1] * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgqnMJG8xRSE",
        "outputId": "b1897c9f-60fc-47b2-e76e-217362402c87"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 84.66%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Function to preprocess user input\n",
        "def preprocess_input(input_text):\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "    tokenizer.fit_on_texts(input_text)\n",
        "    sequences = tokenizer.texts_to_sequences(input_text)\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_review_length)\n",
        "    return padded_sequences\n",
        "\n",
        "# Function to predict sentiment\n",
        "def predict_sentiment(input_text):\n",
        "    preprocessed_input = preprocess_input([input_text])\n",
        "    prediction = model.predict(preprocessed_input)\n",
        "    print(prediction[0][0])\n",
        "    if prediction[0][0] >= 0.5:\n",
        "        return \"Positive\"\n",
        "    else:\n",
        "        return \"Negative\"\n"
      ],
      "metadata": {
        "id": "qGyiWYUfxveG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take user input and test sentiment\n",
        "user_input = input(\"Enter a movie review: \")\n",
        "sentiment = predict_sentiment(user_input)\n",
        "print(\"Predicted sentiment:\", sentiment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08uHJtaqxywr",
        "outputId": "5eb585c0-7834-4ea7-813d-f0bf8778e4c6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a movie review: movie is worthless\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "0.48169827\n",
            "Predicted sentiment: Negative\n"
          ]
        }
      ]
    }
  ]
}